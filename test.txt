17. Shortest paths
    We're going to talk about shortest paths for three lectures(我们大概要讲它三次课).Today will be Shortest Paths one(今天讲最短路径第一部).Shortest paths are sort of an application of dynamic programming(最短路径算法是一种动态规划的应用),which we saw last week, and greedy algorithm,which we also saw last week.So, we're going to build that and get some pretty interesting(我们一会要实现它 用一些很有趣的算法)algorithms for an important problem, which is(来解决一些重要的问题 例如)how to get from Alderon to(如果从奥德隆出发),Cambridge as quickly as possible(怎么才能最快到剑桥).OK, when you live in a graph(假设是在地图上走的话).So, there's geometric shortest paths which is a little bit harder(几何学上有几种最短路径 那比较复杂).Here, we're just going to look at shortest paths in graphs(但这里 我们只关注图的最短路径).Now, hopefully you all know what a path in a graph is(我想你们都应该知道 图的路径是什么了).But, so, very quick review in particular(但还是简单地回顾下)because we're going to be looking at weighted graphs(因为我们准备研究加权的图).So, the usual setup: suppose we have directed graph, G,(那一般前提是 假设我们有个有向图G)have some vertices, some edges(有一些顶点 一些边).We have edge weights, make it a little more interesting(已知边的权重 这会使得图更加有趣).So, this is just a real number on each edge(权重就是每条边上的一个实数).So, edge weights are usually given by function, w(权重可以用函数W来表示).For every edge, you get a real number(对于每条边 都有一个实数).
    We're going to use some simple notation for paths(我们会用一些简单的符号来表示路径)called a path, p, starts at some vertex(比如路径p 起点是某个顶点),and it goes to some other vertex, and so on(经过另一个顶点 等等).Say the last vertex is v_k, and(最后一个顶点是v_k)each of these should be a directed edge in the digraph(这些都是有向图里面的有向边).So, this is a directed path(所以 这是一条有向的路径).Path to respect edges in here(它由对应的这些边组成).And, we'll say that the weight of such a path(然后 一条路径的总权值)is just the sum of the weights of the edges along the path(等于路径上的各边得权值的总和).And, we'll call that w(p)(我们令此为w(p)).This is sum, i equals one to k-1 of w(v_i, v_(i+1))plus one.OK, so just to rub it in(好的 把它画出来).and in particular, how general this can be(那在这里 它一般会是这个样子),we have some path, it starts at some vertex(我们有一条路径 它从某个顶点开始),there's some edge weights along the way(它经过的每条边上有一些权值).This is some arbitrary path in the graph(这代表图里任意一条路径),in some hypothetical graph(在某一副假想图里的路径).OK, this is mainly to point out that(好 这里主要想讲的是)some of the edge weights could be negative(有些边的权值可能是负值).Some of them could be zero(也有一些可能等于0).This sum here is minus two(这里的和等于-2).And, presumably, the graph is much bigger than this(这幅图可能比这儿要大得多).This is just one path in the graph(这只是图里面的一条路径).We're Usually thingking about simple paths that can't repeat a vertext(我们通常考虑的简单路径不会重复经过一个顶点).But, sometimes we allow that(但有时候 我们又允许有这种情况).
    And then, what we care about is the shortest path(然后 我们关心的是最短的路径).or a Shortest path. Again, this may not be unique(或者是某一条最短路径 因为可能不止一条),but we'll still usually call it the shortest path(但我们通常会称之为最短路径).So, we want the shortest path from some A to some B(我们想求从A点到B点的最短路径).Or, we'll call the vertices u and v(我们设这两点为u和v).And we want this to be some path of minimum possible weight(我们想让路径的总权值尽可能地小),subject to starting at u, and going to v(使得从u到v的路径最短).OK, so that's what we're looking for(好的 这就是我们想要的).In general, give you a vertex u, give you a vertex, v(一般来说 给你起点u和终点v),find a shortest path as quickly as possible(如果要最快地找出最短路径).What's a good algorithm for that(有什么好的算法)?That's the topic for the next three lectures(这就是接下来三次课要讲的内容).We'll usually think about a slightly simpler problem(我们通常会思考一个简单一点的问题),which is just computing the weight of that path(就是如何计算路径的权值),which is essentially computing the distance from A to B(说白了就是计算从A到B的距离).So, we'll call this the shortest path weight from u to v(我们把从u到v的最短路径的权值).And, we'll denote it by delta of(u,v), delta(用(u,v)来表示 这个小写的).So, I mean, it's the weight of the shortest path(那么 它等于最短路径的权值),or a weight of every shortest path(或者说 每条最短路径的权值).Or, in other words(换句话说),it's the Min over the weight of each path from u to v(它等于所有从u到v的路径中的最小值).So, p here is a path(这里的p是一条路径).OK, so you just consider(你只要这么想),there could be a lot of different paths(这里可能有许多不同的路径).There could, in principle, be infinitely many(理论上 这有无数条路径),if you're allowed to repeat vertices(如果允许重复经过顶点的话).You look at all those paths hypothetically(假设 你把所有这些路径都算一遍).You take the minimum weight(然后取最小的权值).
    My next question was going to be(我的下一个问题是),when do shortest paths not exist(什么时候 这条最短路径会不存在)?And you've hit upon one version(你们已经遇到一次这种情况了),which is when you have negative edge weights(就是出现负权值的边的时候).So, in principle, when you have negative edge weights(原则上 当你有负值的边时),some shortest paths may not exist(最短路径就可能不存在)OK, in particular, if I have two vertices, u and v(但实际上 如果我有两个顶点u和v),and I have negative edge weights(而其中又有带负值的边).But when specifically won't I have a(但什么情况下 才会真正地...)single shortest path from u to v(没有一条从u到v的最短路径)?So, if I can find the cycle somewhere along here(如果我在某处找到了一个环) whose total weight, say,(它总的权值是)the sum of all the weights of these images is negative(这些权值的总和是负的),then I get there, I go around as many times as I want(如果我在这里 不断地跑这个环).I keep decreasing the weight(这样总权值就会不断减少)because the weight is negative(因为这条环是负的).I decrease it by some fixed amount(我每走一次就减一个定值),and then I can go to v(然后我再走到v).So, as long as there is a negative weights cycle reachable(只要是在从u到v的路径中)from u that can also reach v(经过了一个负环),then there's no shortest path(这样便不存在最短路径)because if I take any particular path(因为无论我选择哪条路径),I can make it shorter by going around a couple more times(我都可以不断走负环来变得更短).So, in some sense, this is not really a minimum(所以在某种程度上 这不是真的最小值).It's more like an infimum for those who(对于某些数学痴来说)who like to get fancy about such things(这更应该说是一个下确界).But we'll just say that delta of (u,v)(但在这里 我们会记delta(u,v))is minus infinity in this case(为负无穷).There's a negative weights cycle from u to v(因为u和v之间有一个负环).So, that's one case we have to worry about in some sense(所以 这种情况是我们需要注意的).But, as long as there are no negative weight cycles(然而 只要没有负环的话).delta of (u,v)will be something bigger than minus infinity(delta 就会是大于负无穷的值),some finite...bounded below by some finite value(有一个有限的...有一个有限的下界)even if you could have negative weights(就算你有负权的边),but still no negative weights cycle(但没有形成负环的话)for example, there might not be any cycles in your graph(比如说 你的图里没有任何的环).So that's still interesting(那这问题就还值得探讨).And, I guess it's useful to note that(而且 我觉得这样想会更好懂)you can get from A to B in negative infinite time(如果你从A到B花的时间是负无穷).It's great, it's time travel(恭喜你 你穿越了),if the weights happen that correspond to time(假如权值表示的是时间的话).But when else might shortest paths not exist(还有什么情况下最短路径不存在)?So,there's one case,but there's another, simpler case(但还有另一种简单的情况).
    It's not connected. There might not be any path from u to v(顶点没有连起来 从u到v可能一条路径都没有).This set might be empty(路径集合为空).There may be no path from u to v(可能一条从u到v的路径都没有).Here we have to define what happens(这里我们要下一个定义),and here, we'll say it's infinity(当u到v之间没有路径时)if there's no path from u to v(我们设它为无穷大).So, there are these exceptional cases(以上就是特殊情况)plus infinity and minus infinity which are pretty intuitive(一个正无穷 一个负无穷 显而易见),because it takes a really long time(因为它真的要花超长的时间)to get from u to v if there's no path there(来从u到达v).You can't get there from here.OK, but that's the definition(好的 定义完了).Most of the time, this is the case we care about, of course(当然 在很多时候 我们都留意这些情况).Usually this is a finite set(但通常它是一个有限集).OK, good, so that's the definition(好的 这是我们给的定义).Now let me tell you(现在我说).
    We're going to get a few basic structural properties(接下来 我们要学习一些)about shortest paths that will allow us to(最短路径的基本特征)obtain good algorithms finding these paths when they exist(以此来构造好的算法 找出存在的最短路径).And, in particular(特别是),we want to use ideas from dynamic programming(我们想用上动态规划的思想).So, if I want to use dynamic programming(所以 如果我想用到动态规划)to solve shortest paths(来解决最短路径问题),what do I need to establish(我要确定些什么)?What's the first thing I should check(我首先要注意的是什么)?You've all implemented dynamic programming by now(你们都试过写动态规划),so should make complete sense hopefully(应该都有一个全面的理解),at least more sense than it did a couple of weeks ago(至少比前几周没接触过的时候要好),last week, when we learned it(上一周 我们都学过了).Dynamic programming is something that grows on you(动态规划的学习是要积累的).Every year I think I understand it better than the previous year(每一年我都觉得 自己对它有了更好的理解).But, in particular(但有一点),when you learned dynamic programming in this class(当你在课堂上学习了动态规划),there is this nice key property that you should check(你们要注意到一个关键的性质).Yeah?Optimal substructure: good(什么？最优子结构 有见地).This is the phrase you should keep in mind(这个短语你们要牢记).It's not really enough for dynamic programming to be(虽然这个还不足以令动态规划)useful in an efficient way(得到有效利用),but it at least tells you that you should(但至少告诉你你该干什么)..you should be able to try to apply it(你们应该能试着用上它).That's a pretty weak statement, but(这虽然是个很弱的命题 但是)it's something that you should check(也是你们要注意的一点).It's definitely pretty much a necessary condition for(这对于动态规划的有效性而言)dynamic programming to make sense(绝对是一个必要条件).And so, optimal some-structure here means that(那么 最优结构表示的是)if I take some shortest path(当我选定一条最短路径时),and I look at a subpath of that shortest path(我再观察这条最短路径的子路径),I claimed that it too is a shortest path(我肯定它也是一条最短路径).OK, with its respective endpoints(子路径对应的两个端点);obviously not between the same endpoints(显然不都是原路径的两端点).But if I have some shortest path between two endpoints(但如果两端点间 有一条最短路径的话),I take any subpath and that's also the shortest path(我取得任意一条子路径 都是最短子路径).This is one version of optimal substructure(这个最优子结构的一个版本).This one turns out to be true for this setup(这对于这里的前提条件是成立的).And, how should I prove an optimal substructure property(那么 我们该怎么证明一个最优子结构的性质)?Cut and paste(剪贴法).Yep, that works here too(在这里也用得上).I mean, this isn't always true(我的意思是 它不是总是有用).But it's a good technique here(但这里它是一个好方法).So, we're going to think about(好 让我们想想看)and I'll do essentially a proof by picture here(然后我准备画幅图来证明).So, suppose you have some subpath of some shortest path(好的 假如你有一些最短路径的子路径).So, let's say the subpath is x to y(我们设子路径从x到y).And, the path goes from u to v(最优路径是从u到v的).So, we assume that (u,v) is a shortest path(所以我们假设(u,v)是最短路径).We want to prove that(x,y) is a shortest path(我们要证明(x,y)也是最短路径).Well, suppose (x,y) isn't a shortest path(好的 假设(x,y)不是最短路径).Then there is some shorter path that goes from x to y(那么x到y之间就有一条更短的路径).But, if you have some shorter path from x to y than this one(但如果你在x到y之间有一条更短的路径).Then I should just erase this part(那么我只要把这一部分子路径)of the shortest path from u to v(从u到v的最短路径种擦掉),and replace it with this shorter one(然后将它替换为更短的路径).
    OK, so that's a good sign for computing shortest paths(看来求出最短路径 已经指日可待了).I mean, in terms of dynamic programming(我的意思是 就动态规划而言),we won't look directly at dynamic programming here because(我们不会直接对动态规划展开攻略), we are going to aim for greedy(因为我们要采用贪心策略 它更为强大),But, next Monday we'll see some dynamic programming approaches(但在下周一 我们会看到动态规划的方法).Intuitively, there are some pretty natural sub problems here(直观上看 这里很自然地会有一些子问题).I mean, going from u to v(从u到v).Maybe it involves computing shortest paths(它可能包括了)from u to some intermediate point, x(求从u到某个中间点x的最短路径),and then from x to u, something like that(然后再从x到u的最短路径 诸如此类).But thinking about this intermediate point(但是现在想一下中间点)we get something called the triangle inequality(我们知道有三角形不等式).It holds in all sorts of geometric spaces(它在所有的几何空间内都是成立的),but it also holds for shortest paths(对最短路径来说也是成立的),the shortest path from u to v is, at most(从u到v的最短路径 最大不超过),the shortest path from u to x plus(u到x的最短路径加上)the shortest path from x to v(x到v的最短路径).So, this should be pretty natural just from the statement(这个命题看起来相当顺理成章),even more natural if you draw the picture(画个图出来的话 更加好理解).So, we have some vertex, u(我们有个点u).I'm using wiggly lines to denote potentially long paths(我用曲线来表示那些可能更长的路径)as opposed to edges(与边相对).We have some intermediate point, x(我们有个中间点x),and we have some target, v(还有个目的点v),and we are considering these three shortest paths(然后我们考虑这三条最短路径).This is the shortest path from u to v(这条是从u到v的最短路径).
    In particular, which is always more exciting(而且会是 相当意思的算法).

---------
20. Parallel algorithms
    So the last, we only have four more lectures left, and what Professor Demmaine and I have decided to do is give two series of lectures on sort of advanced topics.So, today and Wednesday we're going to(那么 我们准备在今天和星期三)talk about parallel algorithms(讨论并行算法), algorithms where you have more than one processor(这种算法会用到多个处理器)whacking away on your problem(并行地解决问题) . And this is a very hot topic right now(这个课题最近非常火) because all of the chip manufactures(因为现在的那些芯片制造商) are now producing so-called multicore processors(都在生产所谓的多核处理器) where you have more than one processor per chip(每个芯片都有多于一个处理器). So, knowing something about that is good(所以 多了解这些知识有好处). The second topic we're going to cover is going to be caching, (我们的第二个算法是关于缓存)and how you design algorithms for systems with cache(以及如何为有缓存机制的系统设计算法). Right now, we're sort of program to everything(目前来说 我们在编程时) as if it were just a single level of memory(都只用了单一的一层内存), and for some problems(但对于某些问题)that's not an entirely realistic model(这跟现实的模型不完全一样).You'd like to have some model(现实中你用到的模型) for how the caching hierarchy works(需要考虑多级缓存怎么运作), and how you can take advantage of that(以及怎么利用好多层缓存). And there's been a lot of research in that area as well(这个领域人们也已经做了很多研究). So, both of those actually(其实 这两个课题)turn out to be my area of research(都在我的研究范围内). That's fun to me(那对我很有趣).
    So, today we'll talk about parallel algorithms(那么 我们今天讨论的是并行算法).  And the particular topic, it turns out that(关于这个课题 实际上)there are lots of models for parallel algorithms(我们有许多种不同的并行算法模型), and for parallelism(和并行化模型).And it's one of the reasons that(这样的原因是), whereas for serial algorithms(对于串行算法而言),most people sort of have this basic model(人们一般只有一种基础模型)that we've been using(也就我们用的那种). It's sometimes called a random access machine model(他有时候被称为随机存取机器模型),which is what we've been using to analyze things(我们之前的分析就是基于这个模型),whereas in the parallel space(但是在并行的空间里),there's just a huge number of models(还有很多其它的模型),and there is no general agreement(而且还没有一个共识)on what is the best model(认为哪一个才是最佳模型) because there are different machines(因为不同的模型)that are made with different configuratios, etc(它们有不同的构造).And people haven't, sort of, agreed on(而且人们甚至还没确定),even how parallel machines should be organized.(并行模型应该如何组织)So, we're going to deal with a paraticular model(那么 我们准备研究一种并行模型),which goes under the rubric of dynamic multithreading(它是属于动态多线程的一种),which is appropriate for the multicore machines(适合用于多核机器中) that are now being built for shared memory programming(它是为内存共享的编程而设计的).It's not appropriate for what's called(并不适用于所谓的)distributed memory programs particularly(分布式内存编程) because the processors are able to access things(因为每个处理器都有访问内存的权限).And for those, you need more involved models(对于其他的情况 你需要学习更多相关的模型).And so, let me start just by giving an example of(所以 让我们从一个简单的例子开始)how one would write something(看看怎么写并行程序).I'm going to give you a program(我准备给你一个程序) for calculating the nth Fibonacci number in this model(这是用来计算第n个斐波拉起数的模型).This is actually a really bad algorithms(其实我接下来要讲的)which is given you because it's going to be the exponential time algorithms(因为它的复杂度是指数级的),whereas we know from week one or two that you can(然而我们在前两周就学会了)calculate the nth Fibonacci number in how much time?(计算Fibonacci数要花多少时间？)log n time. So, this is two exponentials off of(log n的时间 节省了两个指数)what you should be able to get,(这才是你应该得到的结构 节省了两个指数)OK, two exponentials off.OK, so here's the code(所以 这是代码).OK, so this is essentially the pseudocode we would write(好的 这个就是我们要写的伪代码).
    And let me just explain a little bit about(我来解释一下),we have a couple of key words here we haven't seen before:(有几个关键词我们从没有见过)in particular, spawn and sync(特别是衍生(spawn)和同步(sync)).OK, so spawn, this basically says that(这个衍生其实就是指)the subroutine that you're calling(你正在调用一个子程序), you use it as a keyword before a subroutine,(你把衍生作为一个关键字加在子程序前)that it can execute at the same time as its parent(这样它就跟父程序同时执行).So here, what we say x equals spawn of fib of n minus one(这里 我们说x=spawn fib(n-1))we immediately go onto the next statement(我们立刻转到下一语句).And now, while we're executing fib of n minus one,(现在当我们在计算fib(n-1)的时候)we can also be executing, now,(我们同时也在执行...)this statement which itself will spawn something off(下面这条语句 它本身也会衍生子程序).OK, and we continue, and then we hit the sync statement.(好的 我们继续 然后我们碰到这个同步语句)And, what sync says is,(同步就是说)wait until all children are done.(等待至所有子程序完成)OK,so it says once you get to this point(所以一旦你运行到这里),you've got to wait until everything here has completed(你需要等到所有子程序完成后)before you execute the x plus y(才能继续执行这个x+y)because otherwise you're going to(否则的话 你就要)try to execute the calculation(用还没算出来的x和y)of x plus y without having computed it yet.(来执行x+y这个运算)OK,so that's the basic structure(好的 这就是它的基础结构).What this describes, notice in here we never said(这是说...注意了 我们还未曾说过)how many processors or anything we are running on(我们要用到多少处理器神马的).OK, so this actually is(好吧 这实际上)just describing logical parallelism(只是描述了并行的逻辑)--not the actual parallelism when we execute it.(而不是我们实际的并行化执行)And so,what we need is a scheduler to determine(所以 我们要用到一个调度器来决定)how to map this dynamically unfolding execution(如何把这个动态的 不断延伸的程序)onto whatever processors you have available.(映射到可用的处理器上)OK, so today actually,(好的今天实际上)we're going to talk mostly about scheduling.(我们会集中讲关于调度的内容)and then, next time we're going to talk about(然后下一次 我们就会讨论)specific application algorithms(一些特定的应用算法), and how you analyze them(以及如何去分析它们).So you can view the actual multithreaded computation(那时 你们就能看到真真的多线程计算).If you take a look at the parallel instruction stream(如果你看过并行指令就知道),it's just a directed acyclic graph, OK?(它其实是一个有向非循环图)So, let me show you how that works.(那么 我来讲讲它是怎么工作的)
