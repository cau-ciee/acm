20. Parallel algorithms
    So the last, we only have four more lectures left, and what Professor Demmaine and I have decided to do is give two series of lectures on sort of advanced topics.So, today and Wednesday we're going to(那么 我们准备在今天和星期三)talk about parallel algorithms(讨论并行算法), algorithms where you have more than one processor(这种算法会用到多个处理器)whacking away on your problem(并行地解决问题) . And this is a very hot topic right now(这个课题最近非常火) because all of the chip manufactures(因为现在的那些芯片制造商) are now producing so-called multicore processors(都在生产所谓的多核处理器) where you have more than one processor per chip(每个芯片都有多于一个处理器). So, knowing something about that is good(所以 多了解这些知识有好处). The second topic we're going to cover is going to be caching, (我们的第二个算法是关于缓存)and how you design algorithms for systems with cache(以及如何为有缓存机制的系统设计算法). Right now, we're sort of program to everything(目前来说 我们在编程时) as if it were just a single level of memory(都只用了单一的一层内存), and for some problems(但对于某些问题)that's not an entirely realistic model(这跟现实的模型不完全一样).You'd like to have some model(现实中你用到的模型) for how the caching hierarchy works(需要考虑多级缓存怎么运作), and how you can take advantage of that(以及怎么利用好多层缓存). And there's been a lot of research in that area as well(这个领域人们也已经做了很多研究). So, both of those actually(其实 这两个课题)turn out to be my area of research(都在我的研究范围内). That's fun to me(那对我很有趣).
    So, today we'll talk about parallel algorithms(那么 我们今天讨论的是并行算法).  And the particular topic, it turns out that(关于这个课题 实际上)there are lots of models for parallel algorithms(我们有许多种不同的并行算法模型), and for parallelism(和并行化模型).And it's one of the reasons that(这样的原因是), whereas for serial algorithms(对于串行算法而言),most people sort of have this basic model(人们一般只有一种基础模型)that we've been using(也就我们用的那种). It's sometimes called a random access machine model(他有时候被称为随机存取机器模型),which is what we've been using to analyze things(我们之前的分析就是基于这个模型),whereas in the parallel space(但是在并行的空间里),there's just a huge number of models(还有很多其它的模型),and there is no general agreement(而且还没有一个共识)on what is the best model(认为哪一个才是最佳模型) because there are different machines(因为不同的模型)that are made with different configuratios, etc(它们有不同的构造).And people haven't, sort of, agreed on(而且人们甚至还没确定),even how parallel machines should be organized.(并行模型应该如何组织)So, we're going to deal with a paraticular model(那么 我们准备研究一种并行模型),which goes under the rubric of dynamic multithreading(它是属于动态多线程的一种),which is appropriate for the multicore machines(适合用于多核机器中) that are now being built for shared memory programming(它是为内存共享的编程而设计的).It's not appropriate for what's called(并不适用于所谓的)distributed memory programs particularly(分布式内存编程) because the processors are able to access things(因为每个处理器都有访问内存的权限).And for those, you need more involved models(对于其他的情况 你需要学习更多相关的模型).And so, let me start just by giving an example of(所以 让我们从一个简单的例子开始)how one would write something(看看怎么写并行程序).I'm going to give you a program(我准备给你一个程序) for calculating the nth Fibonacci number in this model(这是用来计算第n个斐波拉起数的模型).This is actually a really bad algorithms(其实我接下来要讲的)which is given you because it's going to be the exponential time algorithms(因为它的复杂度是指数级的),whereas we know from week one or two that you can(然而我们在前两周就学会了)calculate the nth Fibonacci number in how much time?(计算Fibonacci数要花多少时间？)log n time. So, this is two exponentials off of(log n的时间 节省了两个指数)what you should be able to get,(这才是你应该得到的结构 节省了两个指数)OK, two exponentials off.OK, so here's the code(所以 这是代码).OK, so this is essentially the pseudocode we would write(好的 这个就是我们要写的伪代码).
    And let me just explain a little bit about(我来解释一下),we have a couple of key words here we haven't seen before:(有几个关键词我们从没有见过)in particular, spawn and sync(特别是衍生(spawn)和同步(sync)).OK, so spawn, this basically says that(这个衍生其实就是指)the subroutine that you're calling(你正在调用一个子程序), you use it as a keyword before a subroutine,(你把衍生作为一个关键字加在子程序前)that it can execute at the same time as its parent(这样它就跟父程序同时执行).So here, what we say x equals spawn of fib of n minus one(这里 我们说x=spawn fib(n-1))we immediately go onto the next statement(我们立刻转到下一语句).And now, while we're executing fib of n minus one,(现在当我们在计算fib(n-1)的时候)we can also be executing, now,(我们同时也在执行...)this statement which itself will spawn something off(下面这条语句 它本身也会衍生子程序).OK, and we continue, and then we hit the sync statement.(好的 我们继续 然后我们碰到这个同步语句)And, what sync says is,(同步就是说)wait until all children are done.(等待至所有子程序完成)OK,so it says once you get to this point(所以一旦你运行到这里),you've got to wait until everything here has completed(你需要等到所有子程序完成后)before you execute the x plus y(才能继续执行这个x+y)because otherwise you're going to(否则的话 你就要)try to execute the calculation(用还没算出来的x和y)of x plus y without having computed it yet.(来执行x+y这个运算)OK,so that's the basic structure(好的 这就是它的基础结构).What this describes, notice in here we never said(这是说...注意了 我们还未曾说过)how many processors or anything we are running on(我们要用到多少处理器神马的).OK, so this actually is(好吧 这实际上)just describing logical parallelism(只是描述了并行的逻辑)--not the actual parallelism when we execute it.(而不是我们实际的并行化执行)And so,what we need is a scheduler to determine(所以 我们要用到一个调度器来决定)how to map this dynamically unfolding execution(如何把这个动态的 不断延伸的程序)onto whatever processors you have available.(映射到可用的处理器上)OK, so today actually,(好的今天实际上)we're going to talk mostly about scheduling.(我们会集中讲关于调度的内容)and then, next time we're going to talk about(然后下一次 我们就会讨论)specific application algorithms(一些特定的应用算法), and how you analyze them(以及如何去分析它们).So you can view the actual multithreaded computation(那时 你们就能看到真真的多线程计算).If you take a look at the parallel instruction stream(如果你看过并行指令就知道),it's just a directed acyclic graph, OK?(它其实是一个有向非循环图)So, let me show you how that works.(那么 我来讲讲它是怎么工作的)
