　　today, we talk about a particular class of algorithms called greedy algorithms(一类叫做贪婪算法的特殊算法).But we're going to do it in the context of graphs(但我们会涉及一些图论的知识).So, I want to review a little bit about graphs(所以 我们先回顾一下图的相关内容),which mostly you can find in the textbook in appendix B(大部分内容可以在课本的附录B里找到).So, just reminder, a digraph(只是提醒一下 一个Digraph).What's that short for(是什么的简称)?Directed graph, OK?Directed graph,G equals(V, E).OK,has a set, V, of vertices(有一个顶点集合V).and we have a set E which is a subset of V cross V of edges(是V叉乘V条边的子集).So that's a digraph(这是一个有向图).And undirected graph, E contains unordered pairs(在无向图里 E包含的是无序的顶点对).OK, so the number of edges is(那么 边的数量是)whether it's directed or undirected, is O of what(无论有向还是无向 复杂度是多少)?V^2.<br />
　　if the G is connected, we have another bound(如果G是连通的 我们就有另一个界限),the number of edges is at least the number of vertices minus one, OK(至少是顶点数减1)?So there's various ways of representing graphs in computers(计算机有很多不同的表示图的方式),and I'm just going to cover a couple of the important ones(我只讲几个比较重要的).There's actually more. We'll see some more(我们日后会看到更多的).So, the simplest one is what's called an adjacency matrix(最简单的一个 称为邻接矩阵).An adjacency matrix of the graph, G, equals (V, E)(图G=(V, E)的一个邻接矩阵),whereas simplest,I'll let V be the set of integers from one up to n(让V为从1到n的整数集),is the n by n matrix A given by the ij-th at the entry((邻接矩阵是一个n乘n的矩阵A 他的第ij项...)) is simply one if the edge, ij, is in the edge set(如果边集里存在一条边ij---则A[i, j]=1)and zero if ij is not in the edge set(如果边ij不再边集里 则为0).OK, sometimes you have edge weighted graphs(有时候 有些图的边是加权了的),and then sometimes what people will do(那么有时候人们会这样处理)is replace this by edge weights(用边的权重来替换1或0).OK, it will be the weight of the edge from i to j(它变成了边ij的权重).<br />
　　So, let's just do an example of that(举一个例子)just to make sure that our intuition corresponds(来证明我们的直觉)to our mathematical definitions(跟我们的数学定义相符).So,here's an example graph.(这是一个图利)Let's say that's our graph(假设这是我们的图).So let's just draw the adjacency the matrix(画一下它的邻接矩阵).OK, so what this says: is there's an edge from one to one(这里是什么：从1到1是否有一条边相连)?And the answer is no(答案是没有).Is there an edge from one to two?Yes(从1到2呢？有).Is there an edge from one to three here?Yep(有一条边从1到3？ 有).That's the adjacency matrix for this particular graph(这就是这个图特有的邻接矩阵).And so,I can represent a graph as this adjacency matrix(所以 我可以用邻接矩阵来表示一个图).OK,when I represent it in this way(当用这种方式表示时).how much storage do I need(需要多少存储空间)?OK, V^2.OK, and that's what we call a dense representation(这就是所说的稠密表示).OK, it works well when the graph is dense(如果图是稠密的话 它的效果非常好).So, the graph is dense if the number of edges(图是稠密的也就是说 如果边的数量)is close to all of the edges possible(很接近最大可能边数).But for many types of graphs, the number of edges(但对于大多数图来说 边的数量)is much less than the possible number of edges(都会员预案少于最大可能边数).In which case we say the graph is sparse(这种情况我们称图是稀疏的).Can somebody give me an example of a sparse graph(谁能给出一个稀疏图的例子吗)? A class of graphs(一类图):so, I want a class of graphs that as n grows(我想要一类图 在这种图里随着n的增加),the number of edges in the graph doesn't grow as the square(图内边的数量不会按n^2的比例增加). A linked list, so, a chain(一个链表 一条链).OK, if you look at it from a graph theoretically(理论上 如果从图的角度来看),is a perfectly good example only n edges in the chain(这会是一个绝佳的例子：只有n条边)for a chain of length n(存放在一条长为n的链里).So therefore, the number of edges would be order V(因此 边的数量会是O(V)).And in particular, you'd only have one edge per row here(这样一来 这里每一行都只有一条边).What other graphs are sparse(还有什么图是稀疏的)?Good, a planner graph(很好 平面图),a graph that can be drawn in a plane turns out that(一个只能在平面上画出来的图)if it has V vertices has, and V is at least three(如果它有V个顶点 而V至少是3),then it has, at most, three V minus six edges(那么 它最多只有(3V-6)条边).So, it turns out that's order V edges again(所以 结果还是O(V)条边).What's another example of a common graph(还有一种常见图的例子是什么)?Yeah, binary tree, or even actually any tree(没错 二叉树或者是其它任意树),you know, what's called a free tree if you read the appendix(如果你看过附录 你就知道那叫自由树).A tree that just is a connected graph that has no cycles(树是一种没有环的连通图)OK, is another example(这是另一个例子).What's an example of a graph that's dense(稠密图有什么例子)?A complete graph, OK: it's all ones(完全图 这里全部是1).OK, or if you have edge weights(好吧 如果边有权重的话),it would be a completely filled in matrix(这个矩阵会被完全填满).So, this is goode for dense representation(所以它很适用于稠密表示).But sometimes you want to have a sparse representation(但有时候你想要用稀疏表示)so we don't have to spend V^2 space to deal with all of the(不想花费V^2的空间来表示),where most of it's going to be zeros(因为这里很多地方都是0).OK, it's sort of like, if we know it's zero(骄傲一下 既然都是0的话),why bother representing it as zero(人家才不会写得这么麻烦呢)?<br />
　　So, one such representation is an adjacency list representation(好的 有一种方法是用邻接表来表示).Actually, adjacency list of a given vertex is the list(实际上 一个给定顶点的邻接表),which we denote by Adj of V, of vertices adjacent to V(我们用Adj(V)来表示 它记录了与V相邻的顶点).OK, just in terms by their terminology(根据它们的术语),vertices are adjacent, but edges are incident on vertices(顶点之间是邻接的 但边与顶点是关联的).OK, so the incidence is a relation between a vertex and an edge(所以 关联是指顶点与边之间的关系).An adjacency is a relation between two vertices(邻接是指两个顶点之间的关系).OK, that's just the language(这只是叫法不同).Why they use to different terms, I don't know(为什么会有不同的术语 我不知道). So, in the graph, for example(举个例子 在这个图里),the adjacency list for vertex one(顶点1的邻接表)is just the list or the set of two three(是包含2和3的链表或者集合)because one has going out of one are edges to two and three(因为从1出发的边 有一条到2  有一条到3).The adjacency list for two is just three(2的邻接表只有3).For three is the empty set, and for four, it is three(3的邻接表是个空集 4的邻接表是3).So that's the representation(这是这个表示方法).Now, if we want to figure out how much storage(如果想要知道这种表示法)is required for this representation(需要占用多少存储空间的话).We need to understand how long the adjacency list is(那就必须先知道这个邻接表有多长).So, what is the length of an adjacency list of a vertex, V(对于一个顶点V 其邻接表的长度是多少)?What name do we give to that(我们用什么名词来描述)?It's the degree. So, in an undirected graph(那就是度 在一个无向图里),we call it the degree of the vertex(我们称之为顶点的度).This is undirected(这是无向图).In the directed case,(在有向的情况下).If the degree, we call it the out degree for a digraph(我们称之为有向图的出度).So, in the digraph(在有向图里),we have an out degree and an in degree for each vertex(每个顶点都有一个出度和一个入度).So here, the in degree is three(这里入度是3).Here, the out degree is two(这里的出度是2).<br />
　　So, one of the important lemma that comes up is(接下来 我们要讲的一个最重要的引理)what's called the handshaking lemma(叫做握手引理).OK, it's one of these mathmatical lemmas(它是数学引理之一).And so, it comes from a story(好的 我讲个故事).Go to a dinner party(一个晚会派对上), and everybody at the dinner party shakes other people's hands(每个人都要和其他人握手).Some people may not shake anybody's hand(有些人可能一个都没握).OK, that's the handshaking lemma(这就是握手定理).If I take for any graph the degree of the vertex(如果对任意图取顶点的度),and sum them all up, that's how many hands everybody shook(把所有度加起来 也就是所有人握手的总次数),that's actually equal to always twice the number of edges(实际总是等于边数的两倍).Why that can be ture(为什么那个正确).Yeah. Every time you put in an edge(没错 每次你加入一条边),you add one to the degree of each person on each end(你在边的每一个端点都加了1的度).So, it's just two different ways(这只是两种不同的)of counting up the same number of edges(计算边的数量的方法).So, what that says is that for undirected graphs(这对于无向图来说),that implies that the adjacency list representation(它意味着其邻接表表示法),uses how much storage(会占用多少存储空间)?OK, at most, 2E, so order E, but that's not all(最多是2E 所以是O(E)，但还没完).It uses theta of V plus E storage(所以需要(V+E)的空间).And, it's basically the same thing asymptotically(这两者基本上是互相等同的).In fact, it's easier to see in some sense for digraphs(实际上对于有向图而言 从某种程度来看更直观)because for digraphs, what I do is I just add up the out degrees(因为对于有向图 我要做的只是把所有的出度加起来),and that equal to E,(而那会等于E)if I add up the out degrees as equally(将所有出度都加起来).In fact, this is kind of like it amortized analysis(实际上这有点类似平摊分析),if you will, a book keeping analysis(你可以看成是记帐分析),that if I'm adding up the total number of edges(如果我加上所有边的度),one way of doing it is accouting for a vertex by vertex(一种方法是一个顶点一个顶点地计算).OK, so for each vertex, I basically can take each degree(对于每个顶点 基本都能得到它的度), and that allocating of account per edge(把它平摊到每条边上),and then ending up with twice the number of edges(结果刚好是每条边都有2的度),that's exactly accounting type of analysis(这正是记账法分析)that we might do for amortized analysis(我们可以拿来做平摊分析).So, this is a sparse representation(这是一种稀疏表示法),and it's often better than an adjacency matrix(一般都比邻接矩阵要好).One an other hand(另一方面), one of the nice things about an adjacency matrix representation(邻接矩阵表示法的一个优点是)is that each edge can be represented with a single bit(每条边都能用一个单独的位来表示),whereas typical when I'm representing(然而 反观这边)thing with an adjacency list representation(如果用邻接表表示法的话),how many bits am I going to need to represent each adjacency(我需要多少位来表示每个邻接的边)?You'll need order log of V(需要O(log V))to be able to name each different vertex(为了表示每个不同的顶点).OK, the log of the number is the number of bits that I need(log(顶点数)个位来表示一个顶点).So, there are places where adjacency matrix is actually(所以 在某些情况下)a far more efficient representation(邻接矩阵是一个非常有效的表示方法).In particular, if you have a very dense graph(尤其是用来表示一张非常稠密的图时).OK, the other thing I want you to get(另一个需要你们理解的是),is that a matrix and a graph(矩阵和图),they are two ways of looking at the same thing(它们看待同一件事物的两种不同方式).In fact, there's a lot of graph theory that(实际上 有很多图论专门涉及到)when you do things like multiply the adjacency matrix(类似邻接矩阵相乘这样的操作).So, there's a lot of commonality between graphs and matrices(所以 图和矩阵有很多共同之处).<br />
　　So, that's just review.Now I want to get onto today's lecture(现在进入今天要讲的内容).So, this is a good time to review appendix B(这是复习附录B的好机会).There are a lot of great properties in there(里面有很多不错的相关性质),and in particular, there is a theorem that(特别是 里面有一个理论)we're going to talk about today(我们在今天将要介绍到的),which is properties of trees(它是树的性质).Trees are very special kinds of graphs(树是非常特殊的一类图),so I really want you to go and look(真诚地希望你们能回去) to see what the properties are(看一下那些性质是什么).There is six different definitions of trees that are all equivalent(六种不同但又等价的树的定义).I think it's a very good idea(我觉得绝对是物超所值)to go through and read through that theorem(如果你阅读了那个理论的话).It provides a very good basis for the thinking that(会给我们今天要讲的内容)we're going to be doing today(提供一个超棒的思想基础).So today, we're going to talk about minimum spanning trees(今天我们要讲到的是最小生成树).This is one of the world's most important algorithms(这是世界上最重要的算法之一).OK, it is important in distributed systems(它在分布式系统里尤为重要).It's one of the first things that(这是几乎所有分布式系统)almost any distributed system tries to find(第一个想要解决的问题)is a minimum spanning tree of the nodes(就是找出一棵最小生成树)that happened to be alive at any point(所有节点在任意时刻都是活跃的).It was the basis of the billing system for AT&T(它是AT&T的记帐系统的基础)for many years while it was a monopoly(这么多年来 从未被超越).You have a connected undirected graph, G equals (V, E)(你有一个连通的无向图 G=(V, E)),with an edge weight function, w(还有一个给边加权的函数w),which maps the edges into weights that are real numbers(它给每条边都加一个实数的权值).And in today, we're going to make an important assumption(我们将要做一个重要的假设),because what they do in the book is much more general(因为书本上的做法更加一般化),but for simplicity and intuition(但为了简单和直观),I'm going to make this a little bit easier(我要降低一下难度).We're going to assume that all edge weights are distinct(我们假设 所有边的权值都是互异的).What does that mean that this function, w(这个w函数意味着什么)?If all edge weights are distinct(如果所有边的权值都是互异的话)?Who remembers their discrete math(谁还记得离散数学怎么说)?It's injective(它是内映射的).OK, it's one to one(没错 是一对一的).It's not one to one and onto necessarily(而且它不一定是一对一的满映射).And the book, they don't assume that(但在书里 我们不做假设).So, that's the input. The output is a(那么 这是输入 而输出是...)The output is a spanning tree, T(输出是一棵生成树),and by spanning tree, we mean it connects all the vertices(一棵生成树是指 它连接了所有的顶点).OK, and it's got to have minimum weight(而且权重的总和还必须最小).OK, so we can write the weight of the tree is going to be(那这棵树的权重就可以写成是),by that, we mean the sum over all edges that are in the tree(根据定义 它是所有在这棵树里的边的权值)of the weight of the individual edges(加起来的总和).<br />
　　So, let's do an example(好吧 举个例子).OK, so here's a graph(这里有幅图).Such that every vertex is part of the tree(而且每一个顶点都是树的一部分).But it's got to have the minimum weight possible(但这棵树的总权值必须是可能的最小值).<br />
　　So, let's first of all make some observations about this puzzle(我们先来对这问题做一些观察).What I remind you is about the optimal substructure property(我要提醒你的是关于最优子结构的性质)because it turns out minimum spanning tree(因为实际上 最小生成树)has a great optimal substructure propertry(它有最优子结构).OK, so the setup is going to be(好的 这个前提是),we're going to have some minimum tree(我们有一个最小生成树).Let's call that T. And, I'm going to show that with the other edges in the graph(而图里的其它的边),are not going to be shown(我们忽略不画).Now, we want to look at a property of optimal substructure(我们要观察它的最优子结构的特性).And the way I'm going to get that, is(我观察的方法是),I'm going to remove some edge, (u,v)(我要移除一些边(u,v)),move an arbitrary edge, (u,v), in the minimum spanning tree(任意地在最小生成树中移除一条边(u,v)).When I remove the tree, what happens to the tree(对树有什么影响)?Then, T is partitional into two subtrees(然后 T被分成了两棵子树).And, we'll call them T_1 and T_2(我们把它称为T_1和T_2).For example, it just has a single node in it and no edges(举个例子 它可能只有一个顶点而且没有边).So, the theorem that we'll prove(我们要证明的定理)that demonstrates a property of optimal substructure(它阐述了最优子结构的特性).T_1 is a minimum spanning tree for the graph, G_1(T_1是图G_1的最小生成树)a subgraph of G induced by the vertices in T_1((G_1是)一个由T_1的顶点所导出的图G的子图).OK, that is, V_1 is just the vertices in T_1(也就是说 V_1是集T_1中的顶点)is what it means to be induced(这就是导出的意思).So V_1 is the vertices in T_1(V_1是T_1的顶点).So, in this picture, I didn't label it(但在这图里 我没有这样标记).This is T_1. This is T_2. In this picture(这是T_1 这是T_2 在这幅图里),these are the vertices of T_1(这些是T_1的顶点).And, E_1 is the set of pairs of vertices, x and y(E_1是顶点对的集 而x和y则是),that are the edges that are in E_1(E_1里面的边)such that both x and y belong to V_1(这样一来 x和y都属于V_1).So the vertices, the graph(那么这些顶点 这个图)...the subgraph induced by the vertices of T_1(这个由T_1的顶点导出的子图)are just those that connect up things in T_1(它把T_1里的顶点都连了起来),and similarly for T_2(同理 T_2也一样).So, the theorem says that(那么 这个定理说)if I look at just the edges within the graph here, G_1(如果我只观察图G_1里面的边),those that are induced by these vertices(它们是由这些顶点导出的).T_1 is, in fact, a minimum spanning tree for that subgraph(实际上 T_1是这个子图的最小生成树).OK, if I look over here conversely, or correspondingly(好的 相反地 或者说相应的 如果我观察这一边),if I look at the set of edges that are induced(如果我观察这一些由这些顶点)by this set of vertices, the vertices in T_2(由T_2中的顶点所导出的边),in fact, T_2 is a minimum spanning tree on that subgraph(实际上 T_2是这边这个子图的最小生成树).Let's see, if we cut out some edge like five(如果我们试着把这个边5砍掉),let's say we cut out five and if I cut edge five(比方说我们砍掉了5这条边的话),that T_1 would be these four vertices here(那T_1就由这四个顶点组成).If I look at the subgraph induced on that these edges here(如果我观察由这些边所导出的子图).In fact, the six, eight, and three are all(实际上 这个6、8和3的边)edges in a minimum spanning tree for that subgraph(它们全都是这个子图的最小生成树的边).<br />
　　So, let's proof that(所以让我们证明它).Cut and paste(剪贴法).OK, so the weight of T I can express as(好的 T的权值我可以表示为)the weight of the edge I removed(我移除的边的权值),plus the weight of T_1, plus the weight of T_2(加上T_1的权值 加上T_2的权值).So, that's the total weight(那么 这就是总权值).Suppose that there were some T_1 prime that was better than T_1 for G_1(它比T_1更适合图G_1).Suppose I had some better way of forming a spanning tree(假设我有一些更好的生成树).Then I would make up a T prime(那我就能得到一棵T'),which just contained the edges, (u,v)(它包含了边(u,v))and T_1 prime, union T_2(并上T_1' 在并上T_2)So, I would take, if I had a better spanning tree(所以 我会取 如果我有一棵更好的生成树),a spanning tree of lower weight for T_1(它比T_1有更低的权值).And I call that T_1 prime(我把它成为T_1').I just substitute that and make up a spanning tree(我只要把它替换掉 然后重建一棵新的生成树)that consisted of my edge,(u,v)(并上这一条边(u,v)),whatever works well for T_1 prime and whatever works well for T(对T_1' 有效的话 那对T也一样有效).And, that would be a spanning tree(那我们就会有一棵新的生成树).And it would be better than T itself was for G(而它则会比T更适合图G).So, we have this nice property of optimal substructure(所以 我们得到了这个最优子结构的特性).OK, I have subproblems that exhibit optimal(我们的子问题会是最优化的).That's one hallmark of dynamic programming(动态规划的标志).What about overlapping subproblems(那重叠子问题呢)?Do I have that property(会不会有这个特性)?Do I have overlapping subproblems over here(对于这类问题 我们会不会有)for this type of problem(重叠子问题的特性)?If I look at simple ordering of taking out the edges(如果我只是简单地改改取出的顺序),I'm going to end up with a whole bunch of overlapping subproblems(那么我会得到一大堆重叠的子问题).Yeah, OK, so what does that suggest we use as an approach(好的 这说明我们要怎么做)?Dynamic programming(动态规划).But it turns out that minimum spanning tree(但隐藏剧情是 这个最小生成树)exhibit an even more powerful property(它还有一个更强大的特性).<br />
　　And that, we call, the hallmark, for greedy algorithms(这就是 贪心算法的标志),which says that a locally optimal choice is globally optimal(它指的是 一个局部最优解也是全局最优解).It turns out you can do even better that dynamic programming(实际上你做的会比动态规划还要好).So let's let T be the MST of our graph(设T为我们的图的MST).And, let's let A be any subset of V(令A是V的任意子集),so, some subset of vertices(也就是 顶点的子集).And now, let's suppose that edge (u,v) is the least weight edge(现在 我们假设边(u,v)是 连接着A到A的补集)connecting our set A to A complement(),that is,V minus A(也就是V-A的 有着最小权值的边).Then the theorem says that (u,v) is in the minimum spanning tree(那么这个定理就说 边(u,v)属于最小生成树).So let's just take a look at our graph over here(我们先观察一下我们的图).OK, so let's take(我们取...),so one thing I could do for A is just take a singleton node(我们可以对A做的一件事是 取一个单元素点).So, I take a singleton node(那我选一个单元素点).let's say this guy here, that can be my A(假设是它 它是我们的A),and everything else is V minus A(然后其他所有顶点都属于V-A).And I look at the least weight edge(我观察最小权值边)connecting this to everything else(连结这一点和其他所有点的边).Well, there are only two edges that connect it to everything else(好吧 这有两条边连接它和其他的点).The theorem says, the lighter one is in the minimum spanning tree(这个小一点的边 它属于最小生成树).let's take a look at these three vertices(我们观察这三个顶点)connected to this set of vertices(它们和这一个顶点相连).I have three edges is going across(我们有三条连接的边).The least weight one is five(权值最小的是5).That's the minimum spanning tree(它就属于最小生成树).Or, I can cut it this way(或者 我可以这样划分).OK, the ones above(上面这一个),the edges going down are seven, eight, and 14(从上面下来的边有 14、8和7).Seven is the least weight(7是最小的).It's in the minimum spanning tree(它属于最小生成树).So, in some sense, that's a local property(某种程度上 它是一个局部性质)because I don't have to look at what the rest of the tree is(因为我不用管树的其他部分).I'm just looking at some small set of vertices if I wish(我只要看到一小部分顶点就好),and I say, well, if I wanted to connect that set of vertices(我说 好吧 如果我要把这个顶点集)to the rest of the world, what would I pick(连接到外面的世界去)?I'd pick the cheapest one, that's the greedy approach(我会选最便宜的那条边 这就是贪心的做法).So, we have (u,v)is the least weight edge connecting A to V minusA(那么 边(u,v)是连接A到V-A的权值最小的边).So, let's suppose that this edge,(u,v)(我们假设这条边(u,v)),is not in the minimum spanning tree(它不属于最小生成树).Then, we're going to cut paste(我们要用剪贴法).<br />
　　So, we are going to do an algorithm called Prim's algorithm(我们要用一种叫Prim的算法来实现它).Prim eventually became a very high-up at AT&T(Prim现在在AT&T里混得风生水起)and it was used in all of the billing code for AT&T for many years(AT&T所有的记帐代码都用了它好多年).He was very high up at Bell Labs(他在贝尔实验室里位高权重)back in the heyday of Bell Laboratories(而且那时还是在贝尔实验室的全盛时期).So, here's the idea(下面是它的思路).What we're going to do is we're going to maintain(我们要做的是)V minus A as a priority queue(把V-A维护成一个优先队列).We'll call it Q(我们称它为Q).And each vertex, we're going to key each vertext in Q(Q里的每一个顶点 我们都赋一个键值给它)withe the weight of the least weight edge(那就是连接V-A和A之间的),connecting it to a vertex in A(权值最小的边的权值).So here's the code(下面是伪代码).So, we're going to start out with Q being all vertices(一开始 Q包含了所有的顶点).So, we start out with A being if you will, the empty set(我们一开始把A设成是空集 根据个人喜好).OK, and what we're going to do it is the least weight edge(因为我们要求的是权值最小的边),therefore, for everything in the priority queue(因此 优先队列里的所有权值)is basically going to be infinity(一开始都会设成正无穷)because none of them have any edges(因为A和V-A之间没有变相连).The least weight edge to the empty set is going to be empty(到空集的权值最小边为空).And then, we're going to start out with one guy(接着 我们从一个顶点开始).We'll call him S(我们称它为S),which will set to zero for some arbitrary S in V(我们会从V中任意选一点S 设为0).And then, the main part of the algorithm kicks in(然后就是算法的主体).<br />
　　So that's our initialization(这是我们的初始化步骤).So, while Q is not empty(所以当Q不为空集时),we get the smallest element out of it(我们从中取出最小的元素).And then we do some stuff(然后再进行其它操作).And then for each step in the adjacency list, in other words(然后对于每一步 在邻接表里 换句话说),everything for which I have an edge going from v to u(对于所有从v到u的边),we take a look, and if v is still in our set V minus A(如果v仍属于集合V-A的话 我就进行查看),so things we've taken out are going to be part of A(所以 取出来的元素就成为了A的一部分).And we just keep repeating the process(持续重复这个过程).OK, we'll do it on the example(举一个例子来说明).And what we do, is every time we bring it in, I keep track of(我们要做的就是 每次加入一条边时),what was the vertex responsible for binging me in(我都追踪哪一个是相关的顶点).And what I claim is that at the end(我要声明的是 在最后),if I look at the set of these pairs that I've made here(当我观察这个顶点对的集合时),V and pi of V, that forms the minimum spanning tree(V还有pi(V)就组成了最小生成树).<br />
　　OK, and then what I'm going to do is find one vertex(接下来 我们要做的是找一个顶点).And I'm going to call him S(把它称为S).So basically, I now make him be zero(然后 把它变为0).And now, what I do, is I execute extract min(现在要做的是 执行取出最小值).So basically, what I'll do is I'll just shade him like this(那基本上 我会给它加个阴影),indicating that he has now joined the set A(表示它现在加入了集合A).So then what we do is we take a look at...(接下来 我们要观察一下)We extract him, and then for each edge in the adjacency list(取出这个点 然后对于它邻接表里的每条边).OK, so for each vertex in the adjacency lists(对于它邻接表里的每个顶点),we're going to look to see if it's still in Q(我们看看他是否仍在队列Q里),that is, in V minus A(即集合V-A).And if so, we are going to(如果还在 那我们就要),and its key value is less than what the value is at the edge there(而且如果它的键值还要小于这条边的权值)we're going to replace it by the edge value(那我们就用边值取代其键值).So, in this case, we're going to replace this by seven(所以在这个例子里 我们就用7来替换它).We're going to replace this by 15(用15来替换它).Because what we're interested in is, what is the cheapest(因为我们感兴趣的是最小的权值)?Now, notice that everything in V minus A(现在 注意到所有V-A里的元素),that is, what's in the priority queue, everything in there(也就是优先队列里面所有顶点).OK, now has its cheapest way of connecting it(现在 它们都有一条最便宜的路径)to the things that I've already removed(跟被我们移除的点相连)the things that are in A(也就是A里面的点).OK, and so now I just, when I actually do that update(那现在我要做一步更新操作),there's actually something implicit going on in this priority queue(实际上 这个优先队列里有一个隐含的操作).And that is that I have to do a decreased key(那就是降低键值的操作).And so, that's implicitly going on(所以 这也隐式地影响到了)when I look at what data structure I'm going to use(我会要选用什么数据结构)to implement that priority queue(来实现这个优先队列).So common data structures for implementing a priority queue are(那一般实现优先队列的数据结构是)A heap, a min heap(堆 一个最小堆).So I have to make sure that I'm actually doing this operation(但我要确保有进行这个操作).I can't just change it and not affect my heap(我不能为了不影响我的堆 而修改它).I find the cheapest thing(找到权值最小的边),and I also have to set, now(同时我们还要),a pointer from each of these guys back to u(设置一些指针 从这些顶点指回u).So here, this guy sets a pointer going this way(所以这个顶点 要设一个指针指回去).This guy sets a pointer going this way(这个顶点设一个指针指回去),and this guy sets a pointer going this way(还有这个顶点设一个指针指回去).That's my pi thing that's going to keep track of(这是pi函数要追踪的)who caused me to set my value to what it is(促使我把键值设为新键值的顶点).So now, we go in and we find the cheapest thing, again(现在回到队列里 找最便宜的点).And we're going to do it fast, too(而且我们要做的快一点).OK, this is a fast algorithm(这是一个快速算法).OK, so now we're going to go do this again(现在要再进行同样的步骤).So now, what's the cheapest thing to extract(现在要取出的最便宜的是哪一个)?This guy here, right? So, we'll take hime out(这个顶点 是吧? 将它取出来).<br />
　　OK, so let's see, this part here costs me order V, right(看这里 这一部分花费O(V)是吧)?OK, and this part(还有这部分).Well, we're going to go through this loop how many times(嗯嗯 我们做了这个循环多少次)?V times(V 次).It's V elements we put into the queue(有V个元素放进队列里).We are not inserting anything. We're just taking them out.(没有进行任何插入 只是将他们取出来).This goes V times(所以这是|V|次).OK, and we do a certain number of extract Mins(然后还有几个取出最小值操作).So, we're going to do order V extract Mins(所以 我们要O(V)次取出最小值).And then we go to the adjacency list(然后到了邻接表),we have these implicit decreased keys for this stuff here(但这里还有一些隐含的降低键值的操作).OK, and so how many implicit decreased keys do we have(有多少因喊得降低键值操作)?That's going to be the expensive thing(这将会是昂贵的开销).At most order E(没错 最多是O(E)).I'm summing up the degrees of all the vertices(我把所有顶点的度加起来).That's how many times I actually execute that(那就是实际的执行次数).So the time overall is order V times(所以总共的时间是O(V)乘以)time for whatever the extract Min is(取出最小值所需的时间)plus E times the time for decreased key(加上E乘以降低键值的时间).So now, let's look at data structures(现在 我们再看数据结构),and we can evaluate for different data structures(在不同的数据结构下做评估)what this formula gives us(看看这条公式会变成怎样).So, the simply is an unsorted array(是一个无序数组).How much time does it take me to extract the minimum element(我要花费多少时间取出最小元素)?order V in this case because it's an array of size V(是O(V)因为它是一个大小为V的数组).And, to do a decreased key(还有降低键值操作),I can do it in order one(我可以在O(1)时间内完成).So, the total is V^2(所以总共是O(V^2)).Or, how about a binary heap(或二叉堆)?to do an extract Min in a binary heap will cost me what(从二叉堆里取最小值的开销是多少)?O of log V.Decrease key will cost me(O(log V) 那降低键值ne).O of log V, because basically you just have to shift value(O(logV),因为基本上只需要把修改的值向上渗透).And the total cost therefore is(所以是O(log V) 那总开销是)?E log V.Which is better(哪个更好)?It depends(看情况)If it's a dense graph(如果是一个稠密图),E is close to V^2, the array is better(E近似等于V^2 用数组比较好).But if it's a sparse graph(但如果是一个稀疏图),and E is much smaller than V^2(E远小于V^2),then the binary heap is better(那么二叉堆会比较好).So that motivated the invention of a data structure(这催生了一种新的数据结构).OK, called a Fibonacci Heap(称为斐波那契堆), because it's an amortized data structure(因为它是一种平摊数据结构).With that data structure, you can do extract Min in order log V amortized time(你可以在O(log V)的平摊时间内取出最小值).And remarkably, you can do decreased key in order one amortized(更酷炫的是 你能在O(1)平摊时间内降低键值).And the total cost,E plus V log V(总时间 是E+VlogV).It's worst-case(它其实是最坏情况).Kruskal's Algorithm in the book(书里的Kruskal算法)uses another data structure(它使用另一种平摊数据结构)called a disjoint set data structure(成为不相交集合数据结构),which also runs in E log V(同样也花费E log V).The best algorithm is a randomized algorithm(那是一个随机算法),and it gives you order V plus E expcted time(它的期望时间是O(V+E)).
